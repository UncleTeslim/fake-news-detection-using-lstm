{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192be32c",
   "metadata": {},
   "source": [
    "# Fake news detetction using stance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c3300",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55ae7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keybert import KeyBERT\n",
    "from newsapi import NewsApiClient\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout, Input, concatenate\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1ec2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = pd.read_csv(\"train_bodies.csv\")\n",
    "stance = pd.read_csv(\"train_stances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5940b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# count=0\n",
    "# for i in tqdm(range(stance.shape[0])):\n",
    "#     for j in range(body.shape[0]):\n",
    "#         if body.loc[j,'Body ID']==stance.loc[i,'Body ID']:\n",
    "#             stance.loc[i,'articleBody'] = body.loc[j,'articleBody']\n",
    "\n",
    "# stance.to_csv('data_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a22d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated   \n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree   \n",
       "\n",
       "                                         articleBody  \n",
       "0  Danny Boyle is directing the untitled film\\n\\n...  \n",
       "1  Hundreds of Palestinians were evacuated from t...  \n",
       "2  30-year-old Moscow resident was hospitalized w...  \n",
       "3  (Reuters) - A Canadian soldier was shot at the...  \n",
       "4  Fear not arachnophobes, the story of Bunbury's...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_combined.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3fa1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unrelated    36545\n",
       "discuss       8909\n",
       "agree         3678\n",
       "disagree       840\n",
       "Name: Stance, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stance_cat'] = data['Stance'].map({'agree':0,'disagree':1,'discuss':2,'unrelated':3}).astype(int)\n",
    "data['Stance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca62b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>stance_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated   \n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree   \n",
       "\n",
       "                                         articleBody  stance_cat  \n",
       "0  Danny Boyle is directing the untitled film\\n\\n...           3  \n",
       "1  Hundreds of Palestinians were evacuated from t...           0  \n",
       "2  30-year-old Moscow resident was hospitalized w...           3  \n",
       "3  (Reuters) - A Canadian soldier was shot at the...           3  \n",
       "4  Fear not arachnophobes, the story of Bunbury's...           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72577205",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines  = data['Headline'].to_list()\n",
    "bodies = data['articleBody'].to_list()\n",
    "stance = data['stance_cat'].values.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ebc653",
   "metadata": {},
   "source": [
    "### Prepare Dataset for Training\n",
    "Next, we standardize, tokenize, and vectorize the data using the helpful tf.keras.layers.Tokenizer layer.\n",
    "\n",
    "`Standardization` refers to preprocessing the text, typically to remove punctuation or HTML elements to simplify the dataset. Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words, by splitting on whitespace). Vectorization refers to converting tokens into numbers so they can be fed into a neural network. All of these tasks can be accomplished with this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b78f32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "max_seq_length_head = 15\n",
    "max_seq_length_body = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8a6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_tokenizer = Tokenizer(num_words=max_features)\n",
    "headline_tokenizer.fit_on_texts(headlines)\n",
    "head_vocab_size = len(headline_tokenizer.word_index) + 1\n",
    "\n",
    "body_tokenizer = Tokenizer(num_words=max_features)\n",
    "body_tokenizer.fit_on_texts(bodies)\n",
    "body_vocab_size = len(body_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a5db39",
   "metadata": {},
   "source": [
    "### Save Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a46e89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open(\"headline_tokenizer.pickle\", \"wb\")\n",
    "pickle.dump(headline_tokenizer, file_to_store)\n",
    "file_to_store.close()\n",
    "\n",
    "file_to_store = open(\"body_tokenizer.pickle\", \"wb\")\n",
    "pickle.dump(body_tokenizer, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f80bd",
   "metadata": {},
   "source": [
    "### Creating Sequences for both headline and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4384f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs_headline = headline_tokenizer.texts_to_sequences(headlines) \n",
    "padded_docs_headline = pad_sequences(encoded_docs_headline, max_seq_length_head,  padding='post', truncating='post')\n",
    "\n",
    "\n",
    "encoded_docs_body = body_tokenizer.texts_to_sequences(bodies)\n",
    "padded_docs_body = pad_sequences(encoded_docs_body, max_seq_length_body,  padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734150b0",
   "metadata": {},
   "source": [
    "Using Stanfor's 100d GloVe to represent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "478a9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"glove.6B.100d.txt\"\n",
    "\n",
    "def setup_embedding_index():\n",
    "    embedding_index = dict()\n",
    "    f = open(GLOVE_DIR, encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.array(values[1:],dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "    f.close()\n",
    "    return embedding_index\n",
    "\n",
    "embeddings_index = setup_embedding_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06ea08d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_headline = np.zeros((head_vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in headline_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_headline[i] = embedding_vector\n",
    "dims = len(embedding_matrix_headline[0])\n",
    "\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7b60869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_body = np.zeros((body_vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in body_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_body[i] = embedding_vector\n",
    "dims = len(embedding_matrix_body[0])\n",
    "\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e76e5",
   "metadata": {},
   "source": [
    "### Train Test Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "451fac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(len(padded_docs_body)*0.9)\n",
    "\n",
    "headline_train = padded_docs_headline[:split_size, :]\n",
    "headline_test = padded_docs_headline[split_size:, :]\n",
    "\n",
    "body_train = padded_docs_body[:split_size, :]\n",
    "body_test = padded_docs_body[split_size:, :]\n",
    "\n",
    "stance = stance.reshape(-1, 1)\n",
    "labels = stance\n",
    "\n",
    "train_labels = labels[:split_size, :]\n",
    "test_labels = labels[split_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7019a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer for headline\n",
    "input_headline = Input(shape=15, name='input_headline')\n",
    "embedding_headline = Embedding(input_dim = head_vocab_size, output_dim =100 ,\n",
    "                                     weights=[embedding_matrix_headline],\n",
    "                                     input_length = 15, trainable=True)(input_headline)\n",
    "\n",
    "# Input layer for body\n",
    "input_body = Input(shape=40, name='input_body')\n",
    "embedding_body = Embedding(input_dim=body_vocab_size, output_dim=100,\n",
    "                          weights=[embedding_matrix_body],\n",
    "                          input_length=40, trainable=True)(input_body)\n",
    "\n",
    "# Create two paralle Bidirectional LSTM layers for the headline and body\n",
    "lstm_head = Bidirectional(LSTM(64))(embedding_headline)\n",
    "lstm_body = Bidirectional(LSTM(64))(embedding_body)\n",
    "addition_layer = concatenate([lstm_head, lstm_body], axis=1)\n",
    "dense = Dense(64, activation='relu')(addition_layer)\n",
    "\n",
    "# Output layer with softmax activation\n",
    "output = Dense(4, activation='softmax')(dense)\n",
    "\n",
    "# create the model\n",
    "model_combined = Model(inputs=[input_headline, input_body], outputs=output)\n",
    "\n",
    "# compile the model\n",
    "model_combined.compile(optimizer = 'adam', loss =tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b16d8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_headline (InputLayer)    [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " input_body (InputLayer)        [(None, 40)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 15, 100)      388000      ['input_headline[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 40, 100)      2742800     ['input_body[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 128)         84480       ['embedding_2[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 128)         84480       ['embedding_3[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['bidirectional_2[0][0]',        \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           16448       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            260         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,316,468\n",
      "Trainable params: 3,316,468\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17428e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model_combined,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87cfa8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1406/1406 [==============================] - 128s 83ms/step - loss: 0.4919 - accuracy: 0.8169 - val_loss: 0.3007 - val_accuracy: 0.8884\n",
      "Epoch 2/15\n",
      "1406/1406 [==============================] - 107s 76ms/step - loss: 0.2079 - accuracy: 0.9226 - val_loss: 0.1890 - val_accuracy: 0.9298\n",
      "Epoch 3/15\n",
      "1406/1406 [==============================] - 110s 78ms/step - loss: 0.1172 - accuracy: 0.9570 - val_loss: 0.1327 - val_accuracy: 0.9534\n",
      "Epoch 4/15\n",
      "1406/1406 [==============================] - 93s 66ms/step - loss: 0.0741 - accuracy: 0.9727 - val_loss: 0.1158 - val_accuracy: 0.9626\n",
      "Epoch 5/15\n",
      "1406/1406 [==============================] - 99s 70ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.0999 - val_accuracy: 0.9676\n",
      "Epoch 6/15\n",
      "1406/1406 [==============================] - 108s 77ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0945 - val_accuracy: 0.9730\n",
      "Epoch 7/15\n",
      "1406/1406 [==============================] - 108s 77ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.0981 - val_accuracy: 0.9724\n",
      "Epoch 8/15\n",
      "1406/1406 [==============================] - 108s 77ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0866 - val_accuracy: 0.9776\n",
      "Epoch 9/15\n",
      "1406/1406 [==============================] - 106s 75ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0872 - val_accuracy: 0.9786\n",
      "Epoch 10/15\n",
      "1406/1406 [==============================] - 109s 78ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.1030 - val_accuracy: 0.9732\n",
      "Epoch 11/15\n",
      "1406/1406 [==============================] - 104s 74ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0912 - val_accuracy: 0.9782\n",
      "Epoch 12/15\n",
      "1406/1406 [==============================] - 107s 76ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0862 - val_accuracy: 0.9798\n",
      "Epoch 13/15\n",
      "1406/1406 [==============================] - 109s 77ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0916 - val_accuracy: 0.9818\n",
      "Epoch 14/15\n",
      "1406/1406 [==============================] - 111s 79ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0826 - val_accuracy: 0.9822\n",
      "Epoch 15/15\n",
      "1406/1406 [==============================] - 107s 76ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0890 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294740bdf10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combined.fit([headline_train, body_train],  train_labels, \n",
    "                  epochs=15, verbose=1,\n",
    "                validation_data=([headline_test, body_test], test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032664c7",
   "metadata": {},
   "source": [
    "### Save and Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92ffcaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: perfect_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: perfect_model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000029472E13880> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000029472E19220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000029472F2BA90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000029472F102B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# save_model(model_combined, 'perfect_model')\n",
    "\n",
    "# perfect_model = load_model('perfect_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519b129",
   "metadata": {},
   "source": [
    "### Preprocess new input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca2fb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(head, body, model):\n",
    "    encoded_docs_headline = headline_tokenizer.texts_to_sequences([head]) \n",
    "    padded_docs_headline = pad_sequences(encoded_docs_headline, max_seq_length_head, padding='post', truncating='post')\n",
    "    \n",
    "    encoded_docs_body = body_tokenizer.texts_to_sequences([body]) \n",
    "    padded_docs_body = pad_sequences(encoded_docs_body, max_seq_length_body, padding='post', truncating='post')\n",
    "    # print(encoded_docs_headline, encoded_docs_body)\n",
    "    \n",
    "    res = model.predict([padded_docs_headline, padded_docs_body])\n",
    "\n",
    "    stance = {0:\"Agree\",\n",
    "              1:\"Disagree\",\n",
    "              2:\"Discuss\",\n",
    "              3:\"Unrelated\"}\n",
    "    \n",
    "    return stance[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75ac6d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unrelated'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"elon musk buys twitter\", \"hey\", perfect_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "024687f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 90.9M/90.9M [00:29<00:00, 3.10MB/s]\n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 26.5kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 28.0kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:11<00:00, 39.7kB/s] \n",
      "Downloading: 100%|██████████| 350/350 [00:00<00:00, 87.2kB/s]\n",
      "Downloading: 100%|██████████| 13.2k/13.2k [00:00<00:00, 4.39MB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:01<00:00, 216kB/s]  \n"
     ]
    }
   ],
   "source": [
    "key_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a2aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(claim = None):\n",
    "    Agree = 0\n",
    "    Disagree = 0\n",
    "            \n",
    "    isReal = False\n",
    "    isFake = False\n",
    "    data = []\n",
    "    try:\n",
    "\n",
    "        if claim != \"\":\n",
    "            key_words = key_model.extract_keywords(claim, top_n=1, \\\n",
    "                keyphrase_ngram_range=(1,5),stop_words='english')\n",
    "            key_words = key_words[0][0]\n",
    "\n",
    "            newsapi = NewsApiClient(api_key='a5bdaefa54ef4ddcacecfc76d8747434')\n",
    "            result = newsapi.get_everything(q=key_words, page_size=50, \\\n",
    "            language='en', from_param='2022-04-28')\n",
    "\n",
    "            articles = result['articles']\n",
    "        \n",
    "        \n",
    "            for _, article in enumerate(articles):\n",
    "                stance = predict(claim, article['description'], perfect_model)\n",
    "\n",
    "                data.append({\"Title\":article['title'],\n",
    "                            \"Source\": article['source'][\"name\"],\n",
    "                            \"Decription\":article['description'],\n",
    "                            \"Link\":article['url'],\n",
    "                            \"Content\":article['content'],\n",
    "                            \"Stance\":stance})\n",
    "                \n",
    "                if stance == \"Agree\" or stance == \"Discuss\":\n",
    "                    Agree += 1\n",
    "                elif stance == 'Disagree':\n",
    "                    Disagree += 1\n",
    "        else:\n",
    "            # print(\"put claim\")\n",
    "            pass\n",
    "            \n",
    "     \n",
    "        \n",
    "    except ConnectionError as e:\n",
    "        print(e)\n",
    "\n",
    "    if Agree > Disagree:\n",
    "        isReal = True\n",
    "        \n",
    "    else:\n",
    "        isFake = True\n",
    "    \n",
    "    return isReal, isFake, data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a9d679a5875f54adbb7c7e6475863eeb01612f8ce9aa5bd6ae81d34c6682ad7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
